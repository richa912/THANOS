{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read the tokens and parsed tree pickle files\n",
    "\n",
    "with open('Data/Pickle File/'+\"yelp_unk150k.pkl\", 'rb') as f:\n",
    "     sent = pickle.load(f)\n",
    "        \n",
    "with open('Data/Pickle File/'+\"yelp_parsedtree150k.pkl\", 'rb') as f:\n",
    "     Tree = pickle.load(f)\n",
    "        \n",
    "data = zip(Tree, sent)\n",
    "data = list(data)\n",
    "tree_dat = pd.DataFrame(data, columns=['Tree', 'Sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combine the tokens and trees with the ratings from original data\n",
    "\n",
    "dat = pd.read_csv('Data/Yelp Raw Data/'+'raw_150k.csv')\n",
    "df = pd.concat([dat,tree_dat],axis=1)\n",
    "df_final=df[['Tree','Sent','stars']].rename(columns={ 'stars': 'rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randomly schuffle the whole data\n",
    "\n",
    "df_final = df_final.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## seperate the data obtained in 80% train set and 20 % testing set\n",
    "\n",
    "train = df_final[:120001]\n",
    "testing = df_final[120001:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seperate the testing data in 10% dev and 10% test set\n",
    "\n",
    "test = testing[:15000].reset_index(drop=True)\n",
    "dev = testing[15000:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user1/anaconda2/envs/ankit_py3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/user1/anaconda2/envs/ankit_py3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/user1/anaconda2/envs/ankit_py3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "## Sort the train, dev and test set each on basis of length of tokens in ascending order. Sorting is done to increase the training speed so as to avoid the unnecessary padding at word level\n",
    "\n",
    "train['len'] = train.Sent.apply(lambda x : len(x))\n",
    "train.sort_values(by = 'len', inplace = True)\n",
    "train.drop(['len'],inplace = True, axis=1)\n",
    "train.reset_index(drop=True, inplace = True)\n",
    "\n",
    "test['len'] = test.Sent.apply(lambda x : len(x))\n",
    "test.sort_values(by = 'len', inplace = True)\n",
    "test.drop(['len'],inplace = True, axis=1)\n",
    "test.reset_index(drop=True, inplace = True)\n",
    "\n",
    "dev['len'] = dev.Sent.apply(lambda x : len(x))\n",
    "dev.sort_values(by = 'len', inplace = True)\n",
    "dev.drop(['len'],inplace = True, axis=1)\n",
    "dev.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save train, dev and test set to pickle files\n",
    "\n",
    "train.to_pickle('Data/'+'train.pkl')\n",
    "test.to_pickle('Data/'+'test.pkl')\n",
    "dev.to_pickle('Data/'+'dev.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
